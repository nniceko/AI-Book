import tensorflow as tf
import numpy as np
import matplotlib.pylab as plt
from tensorflow.keras.datasets.mnist import load_data
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Flatten
from tensorflow.keras.optimizers import Adam

# MNIST 데이터셋을 로드하여 준비
(train_images, train_labels), (test_images, test_labels) = load_data()

# shape of train_image & test_image : (batch_size, image_height, image_width)
# Input data of RNN : (batch_size, timesteps, input_dim)

# 픽셀값 0~1로 정규화
train_images, test_images = train_images / 255.0, test_images / 255.0

# 데이터 레이블 one hot 코드 변경
one_hot_train_labels = to_categorical(train_labels, 10)
one_hot_test_labels = to_categorical(test_labels, 10)

# 모델 구성
model = Sequential()
model.add(LSTM(units=64, return_sequences=True, input_shape = (28, 28)))
model.add(Flatten())
model.add(Dense(10, activation='softmax'))

# 모델 학습을 위한 최적화 함수 및 손실 함수 등 설정
model.compile(optimizer=Adam(learning_rate=0.001), 
              loss='categorical_crossentropy', metrics=['accuracy'])

# 모델 구조 출력
model.summary()

# 모델 학습 수행
history = model.fit(train_images, one_hot_train_labels, epochs=5, batch_size=32)

# 모델 평가
print("\n=============test results==========")
labels = model.predict(test_images)
print("\n Accuracy: %.4f" % (model.evaluate(test_images, one_hot_test_labels)[1])) 

# 결과 이미지로 출력
fig = plt.figure()
for i in range(10):
    subplot = fig.add_subplot(2, 5, i+1)
    subplot.set_xticks([])
    subplot.set_yticks([])
    subplot.set_title('%d' % np.argmax(labels[i]))
    subplot.imshow(test_images[i],
                   cmap=plt.cm.gray_r)
plt.show()

print("===================================")
